\chapter{Introduction}\label{C:intro}

Good software is distinguished from bad software by design qualities such as security, maintainability, and performance. We are interested in how the design of a programming language and its type system can help achieve these qualities.

It is difficult to determine if a piece of code is trustworthy. Several scenarios can give rise to the issue of trust, such as in a development environment adhering to \textit{code ownership}. In this setting, groups of developers may function as experts over certain components. When their components must interact with code sourced from outside their domain of expertise, they can make false assumptions or violate the internal constraints of other components by using them incorrectly. Another setting involves applications which allow third-party plug-ins, in which case third-party code is sourced from an untrustworthy source. A web mash-up is a particular kind of software that brings together disparate applications into a central service, in which case the disparate applications may be untrustworthy.

A range of methods might be employed to help us determine whether we can trust a piece of code. Sandboxing is one, where the suspect code is executed in a safe, separate environment from the trusted code, but this approach has many shortcomings \cite{Jonathan's papers}. Verification techniques allow for robust analyses on code, but are heavyweight and require the developers to have a deep understanding of the techniques being employed \cite{folklore or citation?}. Lightweight analyses, such as those present in type system, enjoy the benefit of being easy for the developer to use, but existing languages do not provide adequate controls for detecting and isolating untrustworthy components \cite{see citations in Darya's modules paper}.

A qualitative approach to trustworthiness is to develop according to particular guidelines considered to be in good practice. One such guideline is the \textit{principle of least authority}: that software components should only have access to the information and resources necessary for their purpose \cite{saltzer74}. For example, a logger module, which need only append to a file, should not have arbitrary read-write access. Another is \textit{privilege separation}, where the division of a program into components is informed by what resources are needed and how they are to be propagated \textbf{[?]}.

This report is interested in how type systems might enforce more static constraints, putting developers in a more-informed position to make qualitative judgements about the trustworthiness of code.\\

One approach to privilege separation is the \textit{capability} model. A capability is an unforgeable token granting its bearer permission to perform some operation \cite{dennis66}. Resources in a program are only exercised though the capabilities granting them. Although the notion of a capability is an old one, there has been recent interest in the application of the idea to programming language design. Miller has identified the ways in which capabilities should proliferate to encourage \textit{robust composition} --- a set of ideas summarised as ``only connectivity begets connectivity'' \cite{miller06}. In his paradigm, the reference graph of a program is the same as the access graph. This eliminates \textit{ambient authority}, whereby a privilege is exercised without being explicitly declared. This enables one to reason about what privileges a component might exercise by examining its interface. Building on these ideas, Maffeis et. al. formalised \textit{capability-safety} of a language, showing a subset of Caja (a JavaScript implementation) meets this notion \cite{maffeis10}.

In addition to realising privilege separation, capabilities also encapsulate the source of \textit{effects}. An \textit{effect} describes some intensional information about the way in which a program executes \cite{nielson99}. For example, a logger's method might $\kwa{append}$ to a file, and so executing this method would incur $\{ \kwa{File.append} \}$. To be able to do this in a capability-safe language, the logger must have a capability for the $\kwa{File}$. Therefore, the constraints imposed by how capabilities proliferate, also impose constraints on what effects the components of a program may incur.

Capabilities can offer fine-grained control over the way in which privileges are exercised via \textit{confinement}. For example, while we expect the logger's log method to have the $\kwa{append}$ effect, a sloppy or malicious implementation may incur extra effects on the $\kwa{File}$, such as $\kwa{write}$ or $\kwa{close}$. Knowing the logger might incur these extra effects may inform the decision a developer makes about whether or not to trust this particular component.

An effect-system is an extension to a type-system, which track what effects a program might incur, and where. They have been used to do \textbf{this, this, and that}. Some have criticised their verbosity \textbf{lightweight polymorphic effects paper} as a point against their practical adoption. An effect system such as the Talpin-Jouvelot $\kwa{ETL}$ system \textbf{ATAPL?} requires the annotation of all values in a program. This requires the developer to be aware, at all points, of what effects are in scope. \textbf{Is this true of all, or even most, effect systems?} Minor alterations to the signatures and effects of one component might require the labels on all interacting components to change in accordance. This overhead is something the developer must carry with them at all stages of development, affecting their usability in large systems. Successive works have focussed on reducing these issues through techniques such as effect-inference, but the benefit of capabilities for effect-based reasoning has received less attention.

Because capabilities encapsulate effectful privileges, and because capability-safe languages impose constraints on how these privileges can spread throughout the system, this considerably simplifies effect-based reasoning. To incur an effect requires one to possess a capability for the appropriate resource, and whether this resource is captured by a component can be determined by inspecting the type-signatures of the component. The developer need not look at the source code. This is the key contribution of this report: that capability-safety facilitates a low-cost effect-based reasoning with minimal user overhead.

We begin this paper by discussing preliminary concepts involving the formal definition of programming languages (2.1.), effect systems (2.2.), and the capability model (2.3.). Along the way we summarise some existing languages to illustrate these points.

Chapter 3 introduces a pair of languages called $\opercalc$ and $\epscalc$. $\opercalc$ is a typed lambda calculus with a simple notion of capabilities and runtime effects. Every function in $\opercalc$ is annotated, which gives a simple, sound system for determining what effects a piece of code might incur. $\epscalc$ allows for unannotated code by introducing an $\kwa{import}$ construct. At the point of interaction between labelled and unlabelled code, a capability-based reasoning enables us to make a safe inference about what effects the unlabelled code might incur.

Chapter 4 shows how $\epscalc$ might be used practically, and we try to convince the reader that $\epscalc$ can be implemented in existing capability-safe languages in a routine manner. We finish with a literature comparison.
