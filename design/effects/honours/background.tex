\chapter{Background}\label{C:background}

In this section we cover some of the necessary concepts and existing work informing this paper. No prior knowledge is assumed.

\section{Formal Semantics}

\noindent
We will consider a programming language as three sets of rules: the grammar, the static rules, and the dynamic rules. To illustrate each we give rules for a toy language that evaluates basic arithmetic operations on $\mathbb{N}$.

The grammar specifies what strings are syntactically legal in the language. A grammar is specified by giving the different categories of terms, and specifying all the possible forms which instantiate that category. Metavariables range over the terms of the category for which they are named. The conventions for specifying a grammar are based on standard Backur-Naur form \cite{bnf}. Figure 2.1. shows a simple grammar describing integer literals and arithmetic expressions on them.

\begin{figure}[h]

\[
\begin{array}{c}

\begin{array}{lllr}

e & ::= & ~ & exprs: \\
	& | & x & variable \\
	& | & e + e & addition \\
	& | & l & integer~constant \\
	&&\\

\end{array}

\begin{array}{lllr}

\tau & ::= & ~ & types: \\
	& | & \kwa{Int} \\
	&&\\
	
\Gamma & ::= & ~ & contexts: \\
	& | & \varnothing \\
	& | & \Gamma, x: \tau \\
	&&\\

\end{array}

\end{array}
\]

\vspace{-7pt}
\caption{Grammar for arithmetic expressions.}
\label{A sample. }
\end{figure}

The static rules specify the type system and other constraints on terms with certain \textit{well-behavedness} properties. In our case, we're interested in what makes a program \textit{well-typed}, which is to say that execution of the program never gets \textit{stuck} due to type-errors. For example, a well-typed program will never try to add two booleans, because addition only makes sense on numbesr. A well-typed program will never try to evaluate an undefined variable, because variables must be defined.

Static rules are specified by \textit{inference rules}. An inference rule is given as a set of premises above a dividing line which, if they hold, imply the result below the line. An application of an inference rule is called a \textit{judgement}. Judgements take place in typing contexts, denoted by $\Gamma$, which map variables to types. A basic judgement like $\Gamma \vdash e: \tau$ means that executing $e$ will result in a term of type $\tau$ (if it terminates). The contents of $\Gamma$ are specified as a comma-separated sequence of variable-type pairs. The order is irrelevant. A consequence of this convention is that if $\Gamma \vdash e: \tau$, then $\Gamma' \vdash e: \tau$, where $\Gamma$ is contained in $\Gamma'$. When a judgement can be proven from the empty context we leave the left of the turnstile blank, as in $\vdash e: \tau$.

Though our arithmetic language has no subtyping, most interesting languages do. This judgement is written $\tau_1 <: \tau_2$ and it means that values of $\tau_1$ may be provided anywhere instances of $\tau_2$ are expected. Effect systems have another judgement, which ascribes a type and set of effects to an expression. We shall cover this in greater detail later.

\begin{figure}[h]

\noindent
\fbox{$\Gamma \vdash e: \tau$}

\[
\begin{array}{c}

\infer[\textsc{(T-Var)}]
	{\Gamma, x: \kwa{Int} \vdash x: \kwa{Int}}
	{}
~~~
\infer[\textsc{(T-Add)}]
	{\Gamma \vdash e_1 + e_2 : \kwa{Int}}
	{\Gamma \vdash e_1: \kwa{Int} & \Gamma \vdash e_2: \kwa{Int}}
	
\end{array}
\]

\vspace{-7pt}
\caption{Inference rules for typing arithmetic expressions.}
\label{A sample. }
\end{figure}

The dynamic semantics specifies what is the meaning of a legal term. There are different flavorus of dynamic semantics, but the one we use is called \textit{small-step semantics}. This is a set of inference rules specifying how a program is executed. A single application of one of these rules is called a \textit{reduction}.

\begin{figure}[h]

\noindent
\fbox{$e \longrightarrow e$}

\[
\begin{array}{c}

\infer[\textsc{(E-Add1)}]
	{e_1 + e_2 \longrightarrow e_1' + e_2}
	{e_1 \longrightarrow e_1'}
~~
\infer[\textsc{(E-Add2)}]
	{l_1 + e_2 \longrightarrow l_1 + e_2'}
	{e_2 \longrightarrow e_2'}
~~
\infer[\textsc{(E-Add3)}]
	{l_1 + l_2 \longrightarrow l_3}
	{l_1 + l_2 = l_3}

\end{array}
\]


\vspace{-7pt}
\caption{Inference rules for reducing arithmetic expressions.}
\label{A sample. }
\end{figure}

Almost all type systems in which we are interested are \textit{sound}. Soundness is a property that holds between the static and dynamic rules of a language, which says that if a program $e$ is considered well-typed by the static rules, then its reduction under the dynamic rules will never produce a runtime type-error. The exact definition of soundness depends on the semantics under consideration, but it is often split into two parts: progress and preservation. The progress theorem states every term, except those of a particular category called values, can always be reduced by applying some dynamic rule. The preservation theorem is that programs remain well-typed under reduction. Adequate formulations of these two theorems for the language under consideration give us soundness.

In the language of arithmetic expressions, progress and preservation would be the following:

\begin{theorem}[Progress]
If $\Gamma \vdash e: \kwa{Int}$ and $e$ is not an integer constant, then $e \rightarrow e'$.
\end{theorem}

\begin{theorem}[Preservation]
If $\Gamma \vdash e: \kwa{Int}$ and $e \rightarrow e'$ then $\Gamma \vdash e': \kwa{Int}$.
\end{theorem}

These theorems can be proven by structural induction on the typing judgement $\Gamma \vdash e: \kwa{Int}$. This is a common proof technique in formal semantics. A more thorough explanation of this sort of induction can be found in TAPL \cite[p. 31]{tapl}.

Some languages extend the notion of a type system to a \textit{type-and-effect system}. Effects describe intensional information about the way in which a program executes \cite{nielson99}. A judgement like $\kwa{\Gamma \vdash e: \tau~\kw{with} \{ File.write \}}$ can be interpreted as meaning that execution of $e$ will result in a value of type $\tau$ (if it halts), and during execution might perform the $\kwa{write}$ effect on a $\kwa{File}$. This judgement is an upper-bound: it says that the only effects $e$ might have when executed are in the set $\{ \kwa{File.write} \}$. The upper-bound is not tight: if $e$ executes, it may not incur every effect ascribed to it.

\section{ $\stlc$ --- Simply-Typed $\lambda$-Calculus}



The simply-typed $\lambda$-calculus $\stlc$ is a model of computation which incorporates a basic theory of types. It was first described by Alonzo Church \cite{church40}. In this section we will cover the rules of a version of $\stlc$ with subtyping, and summarise its basic properties.


\begin{figure}[h]
\vspace{-5pt}

\[
\begin{array}{lll}

\begin{array}{lllr}

e & ::= & ~ & exprs: \\
	& | & x & variable \\
	& | & e~e & application \\
	& | & v & value \\
	&&\\
	
v & ::= & ~ & values: \\
	& | & \lambda x: \tau . e & abstraction \\
	&&\\
	
\end{array}

& ~~~~~~ &

\begin{array}{lllr}

\tau & ::= & ~ & types: \\
	& | & B & base~type \\
	& | & \tau \rightarrow \tau & arrow~type \\
	&&\\
	
\Gamma & ::= & ~ & contexts: \\
	& | & \varnothing & empty~ctx. \\
	& | & \Gamma, x: \tau & var.~binding \\
	&&\\
	
\end{array}

\end{array}
\]

\vspace{-7pt}
\caption{Grammar for $\stlc$.}
\label{This is the label.}
\end{figure}


Terms in $\stlc$ is based on function abstraction and function application. Types are either drawn from a set of base types B, or constructed using $\rightarrow$ (``arrow''). Given types $\tau_1$ and $\tau_2$, $\rightarrow$ can be used to compose a new type, $\tau_1 \rightarrow \tau_2$, which is the type of function taking $\tau_1$-typed terms as input to produce $\tau_2$-typed terms as output. For example, given $B = \{ \Bool, \Int \}$, the following are examples of valid types: $\Bool$, $\Int$, $\Bool \rightarrow \Bool$, $\Bool \rightarrow \Int$, $\Bool \rightarrow (\Bool \rightarrow \Int)$.

Arrow is right-associative, so $\Bool \rightarrow \Bool \rightarrow \Int = \Bool \rightarrow (\Bool \rightarrow \Int)$. The terms ``arrow-type'' and ``function-type'' are interchangeable. \\

\begin{figure}[h]

\fbox{$\Gamma \vdash e: \tau$}

\[
\begin{array}{c}


\infer[\textsc{(T-Var)}]
	{\Gamma, x: \tau \vdash x: \tau}
	{}
	
~~~~~~
	
\infer[\textsc{(T-Abs)}]
	{\Gamma \vdash \lambda x: \tau_1.e : \tau_1 \rightarrow \tau_2}
	{\Gamma, x: \tau_1 \vdash e: \tau_2} \\[4ex]
	
	
\infer[\textsc{(T-App)}]
	{\Gamma \vdash e_1~e_2: \tau_3}
	{\Gamma \vdash e_1: \tau_2 \rightarrow \tau_3 & \Gamma \vdash e_2: \tau_2}
	~~~~~~
\infer[\textsc{T-Subsume}]
	{\Gamma \vdash e: \tau_2}
	{\Gamma \vdash e: \tau_1 & \tau_1 <: \tau_2 }

\end{array}
\]

	
\fbox{$\tau <: \tau$}

	
\[
\begin{array}{c}


\infer[\textsc{(S-Arrow)}]
	{\tau_1 \rightarrow \tau_2 <: \tau_1' \rightarrow \tau_2'}
	{\tau_1' <: \tau_1 & \Gamma \vdash \tau_2 <: \tau_2'}

~~~~~~

\end{array}
\]

\vspace{-7pt}
\caption{Static rules for $\stlc$.}
\label{This is the label.}
\end{figure}

Static rules for $\stlc$ are summarised in Figure 2.5. There are two \textsc{T-Var} states that a variable bound in some context can be typed as its binding. \textsc{T-Abs} states that a function can be typed in $\Gamma$ if $\Gamma$ can type the body of the function when the function's argument has been bound. \textsc{T-App} states that an application is well-typed if the left-hand expression is a function (has an arrow-type $\tau_2 \rightarrow \tau_3$) and the right-hand expression has the same type as the function's input ($\tau_2$).

\textsc{T-Subsume} is the rule which says you may a type a term more generally as any of its supertypes. For example, if we had base types $\Int$ and $\Real$, and a rule specifying $\Int <: \Real$, a term of type $\Int$ can also be typed as $\Real$. This allows programs such as $(\lambda x: \Real. x)~3$ to type, because $3$ can be widened to a $\Real$ by \textsc{T-Subsumption}.

The only subtyping rule we provide is \textsc{S-Arrow}, which describes when one function is a subtype of another. Note how the subtyping relation on the input types is reversed from the subtyping relation on the functions. This is called \textit{contravariance}. Contrast this with the output type, which preserves the order of the subtyping relation. That is called \textit{covariance}. Arrow-types are said to be contravariant in their input and covariant in their output.

Because there are no axiomatic subtyping rules, there are no provable subtyping judgements in this $\lambda$-calculus. In practice we add extra subtyping judgements for the base-types we have chosen as primitive in our calculus. For example, if $\Int$ and $\kwa{Real}$ were base-types, we might add $\Real <: \Int$ as a rule. This is largely an implementation detail and particular to your chosen set of base-types, so we give no such rules here (but will when describing $\epscalc$).

A useful principle in the design and understanding of subtyping rules is Liskov's substitution principle, which states that if $\tau_1 <: \tau_2$, then instances of $\tau_2$ can be replaced with instances of $\tau_1$ without changing the semantics or correctness of the program \cite{liskov87}. Subtyping rules are not usually semantic-preserving, but we'll occasionally use this ideal to motivate certain rules.


\begin{figure}[h]

\noindent
\fbox{$e \longrightarrow e$}

\[
\begin{array}{c}

\infer[\textsc{(E-App1)}]
	{\hat e_1 \hat e_2 \longrightarrow \hat e_1' \hat e_2~|~\varepsilon}
	{\hat e_1 \longrightarrow \hat e_1'~|~\varepsilon}
	~~~~~~
\infer[\textsc{(E-App2)}]
	{\hat v_1 \hat e_2 \longrightarrow \hat v_1 \hat e_2'~|~\varepsilon} 
	{\hat e_2 \longrightarrow \hat e_2'~|~\varepsilon}\\[4ex]
	
\infer[\textsc{(E-App3)}]
	{ (\lambda x: \hat \tau.\hat e) \hat v_2 \longrightarrow [\hat v_2/x]\hat e~|~\varnothing }
	{}\\[4ex]
	
\end{array}
\]

\noindent
\fbox{$e \longrightarrow^{*} e$}

\[
\begin{array}{c}

\infer[\textsc{(E-MultiStep1)}]
	{\hat e \rightarrow^{*} \hat e~|~\varnothing}
	{}
~~~
\infer[\textsc{(E-MultiStep2)}]
	{\hat e \rightarrow^{*} \hat e'~|~\varepsilon}
	{\hat e \rightarrow \hat e'~|~\varepsilon} \\[3ex]
	
\infer[\textsc{(E-MultiStep3)}]
	{\hat e \rightarrow^{*} \hat e''~|~\varepsilon_1 \cup \varepsilon_2}
	{\hat e \rightarrow^{*} \hat e'~|~\varepsilon_1 & \hat e' \rightarrow^{*} \hat e''~|~\varepsilon_2}
\end{array}
\]
\vspace{-7pt}
\caption{Dynamic rules for $\stlc$.}
\label{This is the label.}
\end{figure}

We give two sorts of reduction rules: $e \longrightarrow e$ (single-step) rules involve a single computational step, while $e \longrightarrow^{*} e$ (multi-step) rules are a sequence of computational steps defined inductively over single-steps. 

\section{Capability Safety}

A \textit{capability} is a unique, unforgeable reference, giving its bearer permission to perform some operation \cite{dennis66}. A piece of code $S$ has \textit{authority} over a capability $C$ if it can directly invoke the operations endowed by $C$; it has \textit{transitive authority} if it can indirectly invoke the operations endowed by a capability $C$ (for example, by deferring to another piece of code with authority over $C$).

In a capability model, authority can only proliferate in the following ways \cite{miller06}:

\begin{enumerate}
	\item By the initial set of capabilities passed into the program (initial conditions).
	\item If a function or object is instantiated by its parent, the parent gains a capability for its child (parenthood).
	\item If a function or object is instantiated by a parent, the parent may endow its child with any capabilities it possesses (endowment).
	\item A capability may be transferred via method-calls or function applications (introduction).
\end{enumerate}

The rules of authority proliferation are summarised as: ``only connectivity begets connectivity''.

Primitive capabilities are called \textit{resources}. Resources model those initial capabilities passed into the runtime from the system environment. A capability is either a resource, or a function or object with (potentially transitive) authority over a capability. An example of a resource might be a particular file. A function which manipulates that file (for example, a logger) would also be a capability, but not a resource. Any piece of code which uses a capability, directly or indirectly, is called \textit{impure}. For example, $\kwa{\lambda x: \kwa{Int} .~x}$ is pure, while $\kwa{\lambda f: File .~f.log(``error~message'')}$ is impure.

A relevant concept in the design of capability-based programming languages is \textit{ambient authority}. This is a kind of exercise of authority over a capability $C$ which has not been explicitly \cite{miller03}. Figure 2.4. gives an example in Java, where a malicious implementation of $\kwa{List.add}$ attempts to overwrite the user's $\kwa{.bashrc}$ file. $\kwa{MyList}$ gains this capability by importing the $\kwa{java.io.File}$ class, but its use of files is not immediate from the signature of its functions.

Ambient authority is a challenge to POLA because it makes it impossible to determine from a module's signature what authority is being exercised. From the perspective of $\kwa{Main}$, knowing that $\kwa{MyList.add}$ has a capability for the user's $\kwa{.bashrc}$ file requires one to inspect the source code of $\kwa{.bashrc}$; a necessity at odds with the circumstances which often surround untrusted code and code ownership.

\begin{figure}[h]

\begin{lstlisting}
import java.io.File;
import java.io.IOException;
import java.util.ArrayList;

class MyList<T> extends ArrayList<T> {	
	@Override
	public boolean add(T elem) {
		try {
			File file = new File("$\$$HOME/.bashrc");
			file.createNewFile();
		} catch (IOException e) {}
		return super.add(elem);
	}	
}
\end{lstlisting}

\begin{lstlisting}
import java.util.List;

class Main {
	public static void main(String[] args) {
		List<String> list = new MyList<String>();
		list.add(``doIt'');
	}
}
\end{lstlisting}

\vspace{-7pt}
\caption{$\kwa{Main}$ exercises ambient authority over a $\kwa{File}$.}
\label{A sample. }
\end{figure}

A language is \textit{capability-safe} if it satisfies this capability model and disallows ambient authority. Some examples include E, Js, and Wyvern. \textbf{Get citations.}

\section{First-Class Modules}

The exact way in which modules work is language-dependent, but we are particularly interested in languages with a first-class module systems. First-class modules are important in capability-safe languages because they mean capability-safe reasoning operates across module boundaries. Because modules are first-class, they must be instantiated like regular objects. They must therefore select their capabilities, and be supplied those capabilities by the proliferation rules of the capability model. In practice, first-class modules can be achieved by having module declarations desugar into an underlying lambda or object representation. This generally requires an ``intermediate representation'' of the language, which is simpler than the one in which programmers write.

Java is an example of a mainstream language whose modules are not first-class. Scala has first-class modules \cite{odersky16}, but is not capability-safe. Smalltalk is a dynamically-typed capability-safe language with first-class modules \cite{bracha10}. Wyvern is a statically-typed capability-safe language with first-class modules \cite{kurilova16}.
